{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Methode :\n",
    "- **Support Vector Machine (SVM)** : Un algorithme de classification qui trouve l'hyperplan optimal dans un espace de grande dimension pour séparer les différentes classes. Il peut également être étendu pour gérer des problèmes non linéaires en utilisant des noyaux.\n",
    "\n",
    "- **Régression logistique** : Un algorithme utilisé pour la classification binaire (et pouvant être étendu à la classification multiclasse) en modélisant la probabilité que chaque classe soit la classe cible à l'aide d'une fonction logistique.\n",
    "- **Random Forest** : Un algorithme d'ensemble utilisé pour la classification et la régression. Il combine les prédictions de plusieurs arbres de décision pour obtenir une prédiction plus robuste et généralement de meilleure qualité.\n",
    "- **Réseaux de neurones** :\n",
    "- **Perceptron ou Multi-perceptron** :\n",
    "- **Gradient Boosting** : Un autre algorithme d'ensemble qui construit des arbres de décision de manière séquentielle, en corrigeant les erreurs des arbres précédents. Cela conduit à un modèle de prédiction puissant.\n",
    "- **Naive Bayes** : Un classificateur probabiliste simple basé sur le théorème de Bayes avec une forte indépendance entre les fonctionnalités. Il est souvent utilisé pour la classification de texte et d'autres tâches où l'indépendance des fonctionnalités est une hypothèse raisonnable.\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15caaa19a1d974d5"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:12.036471200Z",
     "start_time": "2024-03-21T20:55:11.913694800Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_dir_path = '../data/external'\n",
    "d_train = pd.read_csv(data_dir_path + \"/train.csv\")\n",
    "d_test = pd.read_csv(data_dir_path + '/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:12.099594900Z",
     "start_time": "2024-03-21T20:55:12.021281400Z"
    }
   },
   "id": "6e916a0db3fc6cbf",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-traitement des données\n",
    "### Separer les classes de features\n",
    "`y_train` = classes or label\n",
    "`x_train` = features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48fe1759bbce5255"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['id', 'margin1', 'margin2', 'margin3', 'margin4', 'margin5', 'margin6',\n       'margin7', 'margin8', 'margin9',\n       ...\n       'texture55', 'texture56', 'texture57', 'texture58', 'texture59',\n       'texture60', 'texture61', 'texture62', 'texture63', 'texture64'],\n      dtype='object', length=193)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_test.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:12.100676Z",
     "start_time": "2024-03-21T20:55:12.073936400Z"
    }
   },
   "id": "7d32830f2ef146fc",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:12.101718900Z",
     "start_time": "2024-03-21T20:55:12.083183900Z"
    }
   },
   "id": "d4931d9e94624856",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "classes = d_train['species'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:12.157768Z",
     "start_time": "2024-03-21T20:55:12.104920300Z"
    }
   },
   "id": "98c4425f01e72d81",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(99,)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:12.230565900Z",
     "start_time": "2024-03-21T20:55:12.162453Z"
    }
   },
   "id": "89ecbf4bddfdbc22",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       id  species   margin1   margin2   margin3   margin4   margin5  \\\n0       1        3  0.007812  0.023438  0.023438  0.003906  0.011719   \n1       2       49  0.005859  0.000000  0.031250  0.015625  0.025391   \n2       3       65  0.005859  0.009766  0.019531  0.007812  0.003906   \n3       5       94  0.000000  0.003906  0.023438  0.005859  0.021484   \n4       6       84  0.005859  0.003906  0.048828  0.009766  0.013672   \n..    ...      ...       ...       ...       ...       ...       ...   \n985  1575       40  0.060547  0.119140  0.007812  0.003906  0.000000   \n986  1578        5  0.001953  0.003906  0.021484  0.107420  0.001953   \n987  1581       11  0.001953  0.003906  0.000000  0.021484  0.078125   \n988  1582       78  0.000000  0.000000  0.046875  0.056641  0.009766   \n989  1584       50  0.023438  0.019531  0.031250  0.015625  0.005859   \n\n      margin6   margin7  margin8  ...  texture55  texture56  texture57  \\\n0    0.009766  0.027344      0.0  ...   0.007812   0.000000   0.002930   \n1    0.001953  0.019531      0.0  ...   0.000977   0.000000   0.000000   \n2    0.005859  0.068359      0.0  ...   0.154300   0.000000   0.005859   \n3    0.019531  0.023438      0.0  ...   0.000000   0.000977   0.000000   \n4    0.015625  0.005859      0.0  ...   0.096680   0.000000   0.021484   \n..        ...       ...      ...  ...        ...        ...        ...   \n985  0.148440  0.017578      0.0  ...   0.242190   0.000000   0.034180   \n986  0.000000  0.000000      0.0  ...   0.170900   0.000000   0.018555   \n987  0.003906  0.007812      0.0  ...   0.004883   0.000977   0.004883   \n988  0.000000  0.000000      0.0  ...   0.083008   0.030273   0.000977   \n989  0.019531  0.035156      0.0  ...   0.000000   0.000000   0.002930   \n\n     texture58  texture59  texture60  texture61  texture62  texture63  \\\n0     0.002930   0.035156   0.000000   0.000000   0.004883   0.000000   \n1     0.000977   0.023438   0.000000   0.000000   0.000977   0.039062   \n2     0.000977   0.007812   0.000000   0.000000   0.000000   0.020508   \n3     0.000000   0.020508   0.000000   0.000000   0.017578   0.000000   \n4     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n..         ...        ...        ...        ...        ...        ...   \n985   0.000000   0.010742   0.000000   0.000000   0.000000   0.000000   \n986   0.000000   0.011719   0.000000   0.000000   0.000977   0.000000   \n987   0.027344   0.016602   0.007812   0.000000   0.027344   0.000000   \n988   0.002930   0.014648   0.000000   0.041992   0.000000   0.001953   \n989   0.000000   0.012695   0.000000   0.000000   0.023438   0.025391   \n\n     texture64  \n0     0.025391  \n1     0.022461  \n2     0.002930  \n3     0.047852  \n4     0.031250  \n..         ...  \n985   0.018555  \n986   0.021484  \n987   0.001953  \n988   0.002930  \n989   0.022461  \n\n[990 rows x 194 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>species</th>\n      <th>margin1</th>\n      <th>margin2</th>\n      <th>margin3</th>\n      <th>margin4</th>\n      <th>margin5</th>\n      <th>margin6</th>\n      <th>margin7</th>\n      <th>margin8</th>\n      <th>...</th>\n      <th>texture55</th>\n      <th>texture56</th>\n      <th>texture57</th>\n      <th>texture58</th>\n      <th>texture59</th>\n      <th>texture60</th>\n      <th>texture61</th>\n      <th>texture62</th>\n      <th>texture63</th>\n      <th>texture64</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.007812</td>\n      <td>0.023438</td>\n      <td>0.023438</td>\n      <td>0.003906</td>\n      <td>0.011719</td>\n      <td>0.009766</td>\n      <td>0.027344</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.007812</td>\n      <td>0.000000</td>\n      <td>0.002930</td>\n      <td>0.002930</td>\n      <td>0.035156</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.004883</td>\n      <td>0.000000</td>\n      <td>0.025391</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>49</td>\n      <td>0.005859</td>\n      <td>0.000000</td>\n      <td>0.031250</td>\n      <td>0.015625</td>\n      <td>0.025391</td>\n      <td>0.001953</td>\n      <td>0.019531</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000977</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000977</td>\n      <td>0.023438</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000977</td>\n      <td>0.039062</td>\n      <td>0.022461</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>65</td>\n      <td>0.005859</td>\n      <td>0.009766</td>\n      <td>0.019531</td>\n      <td>0.007812</td>\n      <td>0.003906</td>\n      <td>0.005859</td>\n      <td>0.068359</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.154300</td>\n      <td>0.000000</td>\n      <td>0.005859</td>\n      <td>0.000977</td>\n      <td>0.007812</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.020508</td>\n      <td>0.002930</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>94</td>\n      <td>0.000000</td>\n      <td>0.003906</td>\n      <td>0.023438</td>\n      <td>0.005859</td>\n      <td>0.021484</td>\n      <td>0.019531</td>\n      <td>0.023438</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000977</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.020508</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.017578</td>\n      <td>0.000000</td>\n      <td>0.047852</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>84</td>\n      <td>0.005859</td>\n      <td>0.003906</td>\n      <td>0.048828</td>\n      <td>0.009766</td>\n      <td>0.013672</td>\n      <td>0.015625</td>\n      <td>0.005859</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.096680</td>\n      <td>0.000000</td>\n      <td>0.021484</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.031250</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>985</th>\n      <td>1575</td>\n      <td>40</td>\n      <td>0.060547</td>\n      <td>0.119140</td>\n      <td>0.007812</td>\n      <td>0.003906</td>\n      <td>0.000000</td>\n      <td>0.148440</td>\n      <td>0.017578</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.242190</td>\n      <td>0.000000</td>\n      <td>0.034180</td>\n      <td>0.000000</td>\n      <td>0.010742</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.018555</td>\n    </tr>\n    <tr>\n      <th>986</th>\n      <td>1578</td>\n      <td>5</td>\n      <td>0.001953</td>\n      <td>0.003906</td>\n      <td>0.021484</td>\n      <td>0.107420</td>\n      <td>0.001953</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.170900</td>\n      <td>0.000000</td>\n      <td>0.018555</td>\n      <td>0.000000</td>\n      <td>0.011719</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000977</td>\n      <td>0.000000</td>\n      <td>0.021484</td>\n    </tr>\n    <tr>\n      <th>987</th>\n      <td>1581</td>\n      <td>11</td>\n      <td>0.001953</td>\n      <td>0.003906</td>\n      <td>0.000000</td>\n      <td>0.021484</td>\n      <td>0.078125</td>\n      <td>0.003906</td>\n      <td>0.007812</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.004883</td>\n      <td>0.000977</td>\n      <td>0.004883</td>\n      <td>0.027344</td>\n      <td>0.016602</td>\n      <td>0.007812</td>\n      <td>0.000000</td>\n      <td>0.027344</td>\n      <td>0.000000</td>\n      <td>0.001953</td>\n    </tr>\n    <tr>\n      <th>988</th>\n      <td>1582</td>\n      <td>78</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.046875</td>\n      <td>0.056641</td>\n      <td>0.009766</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.083008</td>\n      <td>0.030273</td>\n      <td>0.000977</td>\n      <td>0.002930</td>\n      <td>0.014648</td>\n      <td>0.000000</td>\n      <td>0.041992</td>\n      <td>0.000000</td>\n      <td>0.001953</td>\n      <td>0.002930</td>\n    </tr>\n    <tr>\n      <th>989</th>\n      <td>1584</td>\n      <td>50</td>\n      <td>0.023438</td>\n      <td>0.019531</td>\n      <td>0.031250</td>\n      <td>0.015625</td>\n      <td>0.005859</td>\n      <td>0.019531</td>\n      <td>0.035156</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002930</td>\n      <td>0.000000</td>\n      <td>0.012695</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.023438</td>\n      <td>0.025391</td>\n      <td>0.022461</td>\n    </tr>\n  </tbody>\n</table>\n<p>990 rows × 194 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = d_train.copy()\n",
    "# Initialize the encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode the 'species' column\n",
    "processed_data['species'] = le.fit_transform(processed_data['species'])\n",
    "\n",
    "processed_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:12.287983400Z",
     "start_time": "2024-03-21T20:55:12.234789800Z"
    }
   },
   "id": "fb1563ff72ff60bf",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mise à l'échelle\n",
    "La mise à l'échelle des données, ou normalisation, est une étape cruciale en prétraitement des données. le but :\n",
    "\n",
    "1. **Uniformité**: Elle assure que toutes les caractéristiques numériques contribuent également à l'analyse sans être biaisées par leur échelle d'origine.\n",
    "\n",
    "2. **Meilleure convergence**: Beaucoup d'algorithmes de machine learning, comme les réseaux de neurones et les méthodes de descente de gradient, convergent plus rapidement lorsque les données sont mises à l'échelle.\n",
    "\n",
    "3. **Amélioration des performances**: Certains algorithmes, en particulier ceux qui utilisent des mesures de distance comme k-means ou k-NN, ont de meilleures performances si toutes les caractéristiques sont sur une échelle comparable.\n",
    "\n",
    "4. **Stabilité numérique**: La mise à l'échelle peut aussi aider à éviter des problèmes numériques qui peuvent survenir lorsque les caractéristiques ont des ordres de grandeur très différents.\n",
    "\n",
    "En somme, la mise à l'échelle des données aide à rendre le processus d'apprentissage automatique plus efficace et plus stable."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b3f467d46c7e537"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       id  species   margin1   margin2   margin3   margin4   margin5  \\\n0       1        3  0.088883  0.114287  0.150003  0.022987  0.105264   \n1       2       49  0.066662  0.000000  0.200000  0.091955  0.228070   \n2       3       65  0.066662  0.047620  0.124998  0.045975  0.035085   \n3       5       94  0.000000  0.019046  0.150003  0.034481  0.192976   \n4       6       84  0.066662  0.019046  0.312499  0.057474  0.122806   \n..    ...      ...       ...       ...       ...       ...       ...   \n985  1575       40  0.688887  0.580944  0.049997  0.022987  0.000000   \n986  1578        5  0.022221  0.019046  0.137498  0.632180  0.017542   \n987  1581       11  0.022221  0.019046  0.000000  0.126436  0.701743   \n988  1582       78  0.000000  0.000000  0.300000  0.333339  0.087721   \n989  1584       50  0.266671  0.095236  0.200000  0.091955  0.052627   \n\n      margin6   margin7  margin8  ...  texture55  texture56  texture57  \\\n0    0.031447  0.297875      0.0  ...   0.018181   0.000000   0.016951   \n1    0.006289  0.212763      0.0  ...   0.002274   0.000000   0.000000   \n2    0.018867  0.744676      0.0  ...   0.359096   0.000000   0.033896   \n3    0.062892  0.255324      0.0  ...   0.000000   0.004833   0.000000   \n4    0.050314  0.063826      0.0  ...   0.224999   0.000000   0.124293   \n..        ...       ...      ...  ...        ...        ...        ...   \n985  0.477991  0.191488      0.0  ...   0.563639   0.000000   0.197744   \n986  0.000000  0.000000      0.0  ...   0.397729   0.000000   0.107347   \n987  0.012578  0.085101      0.0  ...   0.011364   0.004833   0.028250   \n988  0.000000  0.000000      0.0  ...   0.193181   0.149755   0.005652   \n989  0.062892  0.382975      0.0  ...   0.000000   0.000000   0.016951   \n\n     texture58  texture59  texture60  texture61  texture62  texture63  \\\n0     0.014635   0.330258   0.000000   0.000000   0.012987   0.000000   \n1     0.004880   0.220178   0.000000   0.000000   0.002599   0.449433   \n2     0.004880   0.073387   0.000000   0.000000   0.000000   0.235957   \n3     0.000000   0.192654   0.000000   0.000000   0.046752   0.000000   \n4     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n..         ...        ...        ...        ...        ...        ...   \n985   0.000000   0.100911   0.000000   0.000000   0.000000   0.000000   \n986   0.000000   0.110089   0.000000   0.000000   0.002599   0.000000   \n987   0.136583   0.155961   0.013513   0.000000   0.072727   0.000000   \n988   0.014635   0.137605   0.000000   0.277413   0.000000   0.022470   \n989   0.000000   0.119258   0.000000   0.000000   0.062338   0.292139   \n\n     texture64  \n0     0.179315  \n1     0.158623  \n2     0.020692  \n3     0.337938  \n4     0.220692  \n..         ...  \n985   0.131038  \n986   0.151723  \n987   0.013792  \n988   0.020692  \n989   0.158623  \n\n[990 rows x 194 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>species</th>\n      <th>margin1</th>\n      <th>margin2</th>\n      <th>margin3</th>\n      <th>margin4</th>\n      <th>margin5</th>\n      <th>margin6</th>\n      <th>margin7</th>\n      <th>margin8</th>\n      <th>...</th>\n      <th>texture55</th>\n      <th>texture56</th>\n      <th>texture57</th>\n      <th>texture58</th>\n      <th>texture59</th>\n      <th>texture60</th>\n      <th>texture61</th>\n      <th>texture62</th>\n      <th>texture63</th>\n      <th>texture64</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.088883</td>\n      <td>0.114287</td>\n      <td>0.150003</td>\n      <td>0.022987</td>\n      <td>0.105264</td>\n      <td>0.031447</td>\n      <td>0.297875</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.018181</td>\n      <td>0.000000</td>\n      <td>0.016951</td>\n      <td>0.014635</td>\n      <td>0.330258</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.012987</td>\n      <td>0.000000</td>\n      <td>0.179315</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>49</td>\n      <td>0.066662</td>\n      <td>0.000000</td>\n      <td>0.200000</td>\n      <td>0.091955</td>\n      <td>0.228070</td>\n      <td>0.006289</td>\n      <td>0.212763</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.002274</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.004880</td>\n      <td>0.220178</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002599</td>\n      <td>0.449433</td>\n      <td>0.158623</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>65</td>\n      <td>0.066662</td>\n      <td>0.047620</td>\n      <td>0.124998</td>\n      <td>0.045975</td>\n      <td>0.035085</td>\n      <td>0.018867</td>\n      <td>0.744676</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.359096</td>\n      <td>0.000000</td>\n      <td>0.033896</td>\n      <td>0.004880</td>\n      <td>0.073387</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.235957</td>\n      <td>0.020692</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>94</td>\n      <td>0.000000</td>\n      <td>0.019046</td>\n      <td>0.150003</td>\n      <td>0.034481</td>\n      <td>0.192976</td>\n      <td>0.062892</td>\n      <td>0.255324</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.004833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.192654</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.046752</td>\n      <td>0.000000</td>\n      <td>0.337938</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>84</td>\n      <td>0.066662</td>\n      <td>0.019046</td>\n      <td>0.312499</td>\n      <td>0.057474</td>\n      <td>0.122806</td>\n      <td>0.050314</td>\n      <td>0.063826</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.224999</td>\n      <td>0.000000</td>\n      <td>0.124293</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.220692</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>985</th>\n      <td>1575</td>\n      <td>40</td>\n      <td>0.688887</td>\n      <td>0.580944</td>\n      <td>0.049997</td>\n      <td>0.022987</td>\n      <td>0.000000</td>\n      <td>0.477991</td>\n      <td>0.191488</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.563639</td>\n      <td>0.000000</td>\n      <td>0.197744</td>\n      <td>0.000000</td>\n      <td>0.100911</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.131038</td>\n    </tr>\n    <tr>\n      <th>986</th>\n      <td>1578</td>\n      <td>5</td>\n      <td>0.022221</td>\n      <td>0.019046</td>\n      <td>0.137498</td>\n      <td>0.632180</td>\n      <td>0.017542</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.397729</td>\n      <td>0.000000</td>\n      <td>0.107347</td>\n      <td>0.000000</td>\n      <td>0.110089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002599</td>\n      <td>0.000000</td>\n      <td>0.151723</td>\n    </tr>\n    <tr>\n      <th>987</th>\n      <td>1581</td>\n      <td>11</td>\n      <td>0.022221</td>\n      <td>0.019046</td>\n      <td>0.000000</td>\n      <td>0.126436</td>\n      <td>0.701743</td>\n      <td>0.012578</td>\n      <td>0.085101</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.011364</td>\n      <td>0.004833</td>\n      <td>0.028250</td>\n      <td>0.136583</td>\n      <td>0.155961</td>\n      <td>0.013513</td>\n      <td>0.000000</td>\n      <td>0.072727</td>\n      <td>0.000000</td>\n      <td>0.013792</td>\n    </tr>\n    <tr>\n      <th>988</th>\n      <td>1582</td>\n      <td>78</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.300000</td>\n      <td>0.333339</td>\n      <td>0.087721</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.193181</td>\n      <td>0.149755</td>\n      <td>0.005652</td>\n      <td>0.014635</td>\n      <td>0.137605</td>\n      <td>0.000000</td>\n      <td>0.277413</td>\n      <td>0.000000</td>\n      <td>0.022470</td>\n      <td>0.020692</td>\n    </tr>\n    <tr>\n      <th>989</th>\n      <td>1584</td>\n      <td>50</td>\n      <td>0.266671</td>\n      <td>0.095236</td>\n      <td>0.200000</td>\n      <td>0.091955</td>\n      <td>0.052627</td>\n      <td>0.062892</td>\n      <td>0.382975</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.016951</td>\n      <td>0.000000</td>\n      <td>0.119258</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.062338</td>\n      <td>0.292139</td>\n      <td>0.158623</td>\n    </tr>\n  </tbody>\n</table>\n<p>990 rows × 194 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale numeric columns. Exclude 'id' and 'species' from being scaled\n",
    "numeric_cols = processed_data.columns.drop(['id', 'species'])\n",
    "processed_data[numeric_cols] = scaler.fit_transform(processed_data[numeric_cols])\n",
    "processed_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:12.402752500Z",
     "start_time": "2024-03-21T20:55:12.267425700Z"
    }
   },
   "id": "3c1d6cfb1c064b54",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n0    0.088883  0.114287  0.150003  0.022987  0.105264  0.031447  0.297875   \n1    0.066662  0.000000  0.200000  0.091955  0.228070  0.006289  0.212763   \n2    0.066662  0.047620  0.124998  0.045975  0.035085  0.018867  0.744676   \n3    0.000000  0.019046  0.150003  0.034481  0.192976  0.062892  0.255324   \n4    0.066662  0.019046  0.312499  0.057474  0.122806  0.050314  0.063826   \n..        ...       ...       ...       ...       ...       ...       ...   \n985  0.688887  0.580944  0.049997  0.022987  0.000000  0.477991  0.191488   \n986  0.022221  0.019046  0.137498  0.632180  0.017542  0.000000  0.000000   \n987  0.022221  0.019046  0.000000  0.126436  0.701743  0.012578  0.085101   \n988  0.000000  0.000000  0.300000  0.333339  0.087721  0.000000  0.000000   \n989  0.266671  0.095236  0.200000  0.091955  0.052627  0.062892  0.382975   \n\n     margin8   margin9  margin10  ...  texture55  texture56  texture57  \\\n0        0.0  0.025639  0.340000  ...   0.018181   0.000000   0.016951   \n1        0.0  0.000000  0.079995  ...   0.002274   0.000000   0.000000   \n2        0.0  0.000000  0.460002  ...   0.359096   0.000000   0.033896   \n3        0.0  0.179489  0.179999  ...   0.000000   0.004833   0.000000   \n4        0.0  0.000000  0.059996  ...   0.224999   0.000000   0.124293   \n..       ...       ...       ...  ...        ...        ...        ...   \n985      0.0  0.025639  0.440004  ...   0.563639   0.000000   0.197744   \n986      0.0  0.384616  0.039998  ...   0.397729   0.000000   0.107347   \n987      0.0  0.051279  0.000000  ...   0.011364   0.004833   0.028250   \n988      0.0  0.487174  0.019999  ...   0.193181   0.149755   0.005652   \n989      0.0  0.051279  0.399996  ...   0.000000   0.000000   0.016951   \n\n     texture58  texture59  texture60  texture61  texture62  texture63  \\\n0     0.014635   0.330258   0.000000   0.000000   0.012987   0.000000   \n1     0.004880   0.220178   0.000000   0.000000   0.002599   0.449433   \n2     0.004880   0.073387   0.000000   0.000000   0.000000   0.235957   \n3     0.000000   0.192654   0.000000   0.000000   0.046752   0.000000   \n4     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n..         ...        ...        ...        ...        ...        ...   \n985   0.000000   0.100911   0.000000   0.000000   0.000000   0.000000   \n986   0.000000   0.110089   0.000000   0.000000   0.002599   0.000000   \n987   0.136583   0.155961   0.013513   0.000000   0.072727   0.000000   \n988   0.014635   0.137605   0.000000   0.277413   0.000000   0.022470   \n989   0.000000   0.119258   0.000000   0.000000   0.062338   0.292139   \n\n     texture64  \n0     0.179315  \n1     0.158623  \n2     0.020692  \n3     0.337938  \n4     0.220692  \n..         ...  \n985   0.131038  \n986   0.151723  \n987   0.013792  \n988   0.020692  \n989   0.158623  \n\n[990 rows x 192 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>margin1</th>\n      <th>margin2</th>\n      <th>margin3</th>\n      <th>margin4</th>\n      <th>margin5</th>\n      <th>margin6</th>\n      <th>margin7</th>\n      <th>margin8</th>\n      <th>margin9</th>\n      <th>margin10</th>\n      <th>...</th>\n      <th>texture55</th>\n      <th>texture56</th>\n      <th>texture57</th>\n      <th>texture58</th>\n      <th>texture59</th>\n      <th>texture60</th>\n      <th>texture61</th>\n      <th>texture62</th>\n      <th>texture63</th>\n      <th>texture64</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.088883</td>\n      <td>0.114287</td>\n      <td>0.150003</td>\n      <td>0.022987</td>\n      <td>0.105264</td>\n      <td>0.031447</td>\n      <td>0.297875</td>\n      <td>0.0</td>\n      <td>0.025639</td>\n      <td>0.340000</td>\n      <td>...</td>\n      <td>0.018181</td>\n      <td>0.000000</td>\n      <td>0.016951</td>\n      <td>0.014635</td>\n      <td>0.330258</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.012987</td>\n      <td>0.000000</td>\n      <td>0.179315</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.066662</td>\n      <td>0.000000</td>\n      <td>0.200000</td>\n      <td>0.091955</td>\n      <td>0.228070</td>\n      <td>0.006289</td>\n      <td>0.212763</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.079995</td>\n      <td>...</td>\n      <td>0.002274</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.004880</td>\n      <td>0.220178</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002599</td>\n      <td>0.449433</td>\n      <td>0.158623</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.066662</td>\n      <td>0.047620</td>\n      <td>0.124998</td>\n      <td>0.045975</td>\n      <td>0.035085</td>\n      <td>0.018867</td>\n      <td>0.744676</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.460002</td>\n      <td>...</td>\n      <td>0.359096</td>\n      <td>0.000000</td>\n      <td>0.033896</td>\n      <td>0.004880</td>\n      <td>0.073387</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.235957</td>\n      <td>0.020692</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.019046</td>\n      <td>0.150003</td>\n      <td>0.034481</td>\n      <td>0.192976</td>\n      <td>0.062892</td>\n      <td>0.255324</td>\n      <td>0.0</td>\n      <td>0.179489</td>\n      <td>0.179999</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.004833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.192654</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.046752</td>\n      <td>0.000000</td>\n      <td>0.337938</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.066662</td>\n      <td>0.019046</td>\n      <td>0.312499</td>\n      <td>0.057474</td>\n      <td>0.122806</td>\n      <td>0.050314</td>\n      <td>0.063826</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.059996</td>\n      <td>...</td>\n      <td>0.224999</td>\n      <td>0.000000</td>\n      <td>0.124293</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.220692</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>985</th>\n      <td>0.688887</td>\n      <td>0.580944</td>\n      <td>0.049997</td>\n      <td>0.022987</td>\n      <td>0.000000</td>\n      <td>0.477991</td>\n      <td>0.191488</td>\n      <td>0.0</td>\n      <td>0.025639</td>\n      <td>0.440004</td>\n      <td>...</td>\n      <td>0.563639</td>\n      <td>0.000000</td>\n      <td>0.197744</td>\n      <td>0.000000</td>\n      <td>0.100911</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.131038</td>\n    </tr>\n    <tr>\n      <th>986</th>\n      <td>0.022221</td>\n      <td>0.019046</td>\n      <td>0.137498</td>\n      <td>0.632180</td>\n      <td>0.017542</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.384616</td>\n      <td>0.039998</td>\n      <td>...</td>\n      <td>0.397729</td>\n      <td>0.000000</td>\n      <td>0.107347</td>\n      <td>0.000000</td>\n      <td>0.110089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002599</td>\n      <td>0.000000</td>\n      <td>0.151723</td>\n    </tr>\n    <tr>\n      <th>987</th>\n      <td>0.022221</td>\n      <td>0.019046</td>\n      <td>0.000000</td>\n      <td>0.126436</td>\n      <td>0.701743</td>\n      <td>0.012578</td>\n      <td>0.085101</td>\n      <td>0.0</td>\n      <td>0.051279</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.011364</td>\n      <td>0.004833</td>\n      <td>0.028250</td>\n      <td>0.136583</td>\n      <td>0.155961</td>\n      <td>0.013513</td>\n      <td>0.000000</td>\n      <td>0.072727</td>\n      <td>0.000000</td>\n      <td>0.013792</td>\n    </tr>\n    <tr>\n      <th>988</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.300000</td>\n      <td>0.333339</td>\n      <td>0.087721</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.487174</td>\n      <td>0.019999</td>\n      <td>...</td>\n      <td>0.193181</td>\n      <td>0.149755</td>\n      <td>0.005652</td>\n      <td>0.014635</td>\n      <td>0.137605</td>\n      <td>0.000000</td>\n      <td>0.277413</td>\n      <td>0.000000</td>\n      <td>0.022470</td>\n      <td>0.020692</td>\n    </tr>\n    <tr>\n      <th>989</th>\n      <td>0.266671</td>\n      <td>0.095236</td>\n      <td>0.200000</td>\n      <td>0.091955</td>\n      <td>0.052627</td>\n      <td>0.062892</td>\n      <td>0.382975</td>\n      <td>0.0</td>\n      <td>0.051279</td>\n      <td>0.399996</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.016951</td>\n      <td>0.000000</td>\n      <td>0.119258</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.062338</td>\n      <td>0.292139</td>\n      <td>0.158623</td>\n    </tr>\n  </tbody>\n</table>\n<p>990 rows × 192 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = processed_data.drop(columns=['id', 'species'])\n",
    "x_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:12.485050500Z",
     "start_time": "2024-03-21T20:55:12.343649800Z"
    }
   },
   "id": "f1c0fd1bf84c98ae",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0       3\n1      49\n2      65\n3      94\n4      84\n       ..\n985    40\n986     5\n987    11\n988    78\n989    50\nName: species, Length: 990, dtype: int32"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = processed_data['species']\n",
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:12.539077Z",
     "start_time": "2024-03-21T20:55:12.411142400Z"
    }
   },
   "id": "808be255ca5b1f43",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:12.637488100Z",
     "start_time": "2024-03-21T20:55:12.537945300Z"
    }
   },
   "id": "e399d1e28da8c98e",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:12.725194500Z",
     "start_time": "2024-03-21T20:55:12.639452600Z"
    }
   },
   "id": "b0b701ab459f05e9",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:12.837689600Z",
     "start_time": "2024-03-21T20:55:12.729179600Z"
    }
   },
   "id": "e12a2fe5d1624af6",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perceptron"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a2aab55f9768641"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:12.876256500Z",
     "start_time": "2024-03-21T20:55:12.841741700Z"
    }
   },
   "id": "25d0d42ddb3e083f",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "scikit-learn estimators should always specify their parameters in the signature of their __init__ (no varargs). <class 'src.models.perceptron_model.PerceptronModel'> with constructor (self, *args, **kwargs) doesn't  follow this convention.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 10\u001B[0m\n\u001B[0;32m      5\u001B[0m perceptron \u001B[38;5;241m=\u001B[39m PerceptronModel()\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Entraînement du modèle sur les données d'entraînement\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m \u001B[43mperceptron\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m    \n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# Prédiction sur les données d'entraînement\u001B[39;00m\n\u001B[0;32m     13\u001B[0m perceptron_pred_train \u001B[38;5;241m=\u001B[39m perceptron\u001B[38;5;241m.\u001B[39mpredict(x_train)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ift712-final-project\\.venv\\Lib\\site-packages\\sklearn\\base.py:1467\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1462\u001B[0m partial_fit_and_fitted \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1463\u001B[0m     fit_method\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpartial_fit\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m _is_fitted(estimator)\n\u001B[0;32m   1464\u001B[0m )\n\u001B[0;32m   1466\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m global_skip_validation \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m partial_fit_and_fitted:\n\u001B[1;32m-> 1467\u001B[0m     \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1472\u001B[0m     )\n\u001B[0;32m   1473\u001B[0m ):\n\u001B[0;32m   1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ift712-final-project\\.venv\\Lib\\site-packages\\sklearn\\base.py:668\u001B[0m, in \u001B[0;36mBaseEstimator._validate_params\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    658\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_params\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    659\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001B[39;00m\n\u001B[0;32m    660\u001B[0m \n\u001B[0;32m    661\u001B[0m \u001B[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    664\u001B[0m \u001B[38;5;124;03m    accepted constraints.\u001B[39;00m\n\u001B[0;32m    665\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m    666\u001B[0m     validate_parameter_constraints(\n\u001B[0;32m    667\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parameter_constraints,\n\u001B[1;32m--> 668\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdeep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m,\n\u001B[0;32m    669\u001B[0m         caller_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[0;32m    670\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\ift712-final-project\\.venv\\Lib\\site-packages\\sklearn\\base.py:243\u001B[0m, in \u001B[0;36mBaseEstimator.get_params\u001B[1;34m(self, deep)\u001B[0m\n\u001B[0;32m    228\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    229\u001B[0m \u001B[38;5;124;03mGet parameters for this estimator.\u001B[39;00m\n\u001B[0;32m    230\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    240\u001B[0m \u001B[38;5;124;03m    Parameter names mapped to their values.\u001B[39;00m\n\u001B[0;32m    241\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    242\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m()\n\u001B[1;32m--> 243\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_param_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    244\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, key)\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m deep \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(value, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget_params\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[1;32m~\\PycharmProjects\\ift712-final-project\\.venv\\Lib\\site-packages\\sklearn\\base.py:217\u001B[0m, in \u001B[0;36mBaseEstimator._get_param_names\u001B[1;34m(cls)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m parameters:\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m p\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;241m==\u001B[39m p\u001B[38;5;241m.\u001B[39mVAR_POSITIONAL:\n\u001B[1;32m--> 217\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    218\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscikit-learn estimators should always \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    219\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspecify their parameters in the signature\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    220\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m of their __init__ (no varargs).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    221\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m with constructor \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    222\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m follow this convention.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mcls\u001B[39m, init_signature)\n\u001B[0;32m    223\u001B[0m         )\n\u001B[0;32m    224\u001B[0m \u001B[38;5;66;03m# Extract and sort argument names excluding 'self'\u001B[39;00m\n\u001B[0;32m    225\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msorted\u001B[39m([p\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m parameters])\n",
      "\u001B[1;31mRuntimeError\u001B[0m: scikit-learn estimators should always specify their parameters in the signature of their __init__ (no varargs). <class 'src.models.perceptron_model.PerceptronModel'> with constructor (self, *args, **kwargs) doesn't  follow this convention."
     ]
    }
   ],
   "source": [
    "from src.models.perceptron_model import PerceptronModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Création d'un objet Perceptron\n",
    "perceptron = PerceptronModel()\n",
    "\n",
    "\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "perceptron.fit(x_train, y_train)    \n",
    "\n",
    "# Prédiction sur les données d'entraînement\n",
    "perceptron_pred_train = perceptron.predict(x_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:57:19.354857Z",
     "start_time": "2024-03-21T20:57:19.304746800Z"
    }
   },
   "id": "c604625c573dd78e",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7dec7c30587233f7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perceptron_pred_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Calcul du taux d'erreur\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m error_rate \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m accuracy_score(y_train, \u001B[43mperceptron_pred_train\u001B[49m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Calcul de la précision\u001B[39;00m\n\u001B[0;32m      5\u001B[0m precision \u001B[38;5;241m=\u001B[39m precision_score(y_train, perceptron_pred_train)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'perceptron_pred_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calcul du taux d'erreur\n",
    "error_rate = 1 - accuracy_score(y_train, perceptron_pred_train)\n",
    "\n",
    "# Calcul de la précision\n",
    "precision = precision_score(y_train, perceptron_pred_train)\n",
    "\n",
    "# Calcul du rappel\n",
    "recall = recall_score(y_train, perceptron_pred_train)\n",
    "\n",
    "# Calcul du score F1\n",
    "f1 = f1_score(y_train, perceptron_pred_train)\n",
    "\n",
    "print(\"Taux d'erreur:\", error_rate)\n",
    "print(\"Précision:\", precision)\n",
    "print(\"Rappel:\", recall)\n",
    "print(\"Score F1:\", f1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-21T20:55:12.944309300Z"
    }
   },
   "id": "606f0e27a6c789e4",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2035af58f6f0e32b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Création d'un objet SVM avec un kernel gaussien (RBF)\n",
    "svm_classifier = SVC(kernel='rbf')\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Prédiction sur les données d'entraînement (facultatif)\n",
    "svm_pred_train = svm_classifier.predict(x_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:13.499359400Z",
     "start_time": "2024-03-21T20:55:12.961083300Z"
    }
   },
   "id": "e6c1ca48320a8162",
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db673ead39b77ae2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Création d'un objet LogisticRegression\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "logistic_regression.fit(x_train, y_train)\n",
    "\n",
    "# Prédiction sur les données d'entraînement (facultatif)\n",
    "predictions_train = logistic_regression.predict(x_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:14.065900500Z",
     "start_time": "2024-03-21T20:55:13.499359400Z"
    }
   },
   "id": "770313957263ab7d",
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Réseaux de neurones"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99a4914a5d166709"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Création d'un objet MLPClassifier (réseau de neurones)\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "mlp_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Prédiction sur les données d'entraînement (facultatif)\n",
    "predictions_train = mlp_classifier.predict(x_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:18.036219Z",
     "start_time": "2024-03-21T20:55:14.062708800Z"
    }
   },
   "id": "fd4357e3bb5adb65",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T20:55:18.044675500Z",
     "start_time": "2024-03-21T20:55:18.038021200Z"
    }
   },
   "id": "c32be993a36e694",
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
