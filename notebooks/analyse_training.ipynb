{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Methode :\n",
    "- **Support Vector Machine (SVM)** : Un algorithme de classification qui trouve l'hyperplan optimal dans un espace de grande dimension pour séparer les différentes classes. Il peut également être étendu pour gérer des problèmes non linéaires en utilisant des noyaux.\n",
    "\n",
    "- **Régression logistique** : Un algorithme utilisé pour la classification binaire (et pouvant être étendu à la classification multiclasse) en modélisant la probabilité que chaque classe soit la classe cible à l'aide d'une fonction logistique.\n",
    "- **Random Forest** : Un algorithme d'ensemble utilisé pour la classification et la régression. Il combine les prédictions de plusieurs arbres de décision pour obtenir une prédiction plus robuste et généralement de meilleure qualité.\n",
    "- **Réseaux de neurones** :\n",
    "- **Perceptron ou Multi-perceptron** :\n",
    "- **Gradient Boosting** : Un autre algorithme d'ensemble qui construit des arbres de décision de manière séquentielle, en corrigeant les erreurs des arbres précédents. Cela conduit à un modèle de prédiction puissant.\n",
    "- **Naive Bayes** : Un classificateur probabiliste simple basé sur le théorème de Bayes avec une forte indépendance entre les fonctionnalités. Il est souvent utilisé pour la classification de texte et d'autres tâches où l'indépendance des fonctionnalités est une hypothèse raisonnable.\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15caaa19a1d974d5"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:17.771595900Z",
     "start_time": "2024-03-22T22:06:16.963226800Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Leaf Classificatio"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "625a4872a7bd651e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_dir_path = '../data/external'\n",
    "d_train = pd.read_csv(data_dir_path + \"/train.csv\")\n",
    "d_test = pd.read_csv(data_dir_path + '/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:17.846168800Z",
     "start_time": "2024-03-22T22:06:17.769538300Z"
    }
   },
   "id": "6e916a0db3fc6cbf",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-traitement des données\n",
    "### Separer les classes de features\n",
    "`y_train` = classes or label\n",
    "`x_train` = features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48fe1759bbce5255"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['id', 'species', 'margin1', 'margin2', 'margin3', 'margin4', 'margin5',\n       'margin6', 'margin7', 'margin8',\n       ...\n       'texture55', 'texture56', 'texture57', 'texture58', 'texture59',\n       'texture60', 'texture61', 'texture62', 'texture63', 'texture64'],\n      dtype='object', length=194)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:17.875102300Z",
     "start_time": "2024-03-22T22:06:17.848304600Z"
    }
   },
   "id": "f6a40e73232749c4",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['id', 'margin1', 'margin2', 'margin3', 'margin4', 'margin5', 'margin6',\n       'margin7', 'margin8', 'margin9',\n       ...\n       'texture55', 'texture56', 'texture57', 'texture58', 'texture59',\n       'texture60', 'texture61', 'texture62', 'texture63', 'texture64'],\n      dtype='object', length=193)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_test.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:17.877209400Z",
     "start_time": "2024-03-22T22:06:17.859273900Z"
    }
   },
   "id": "7d32830f2ef146fc",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:17.879952100Z",
     "start_time": "2024-03-22T22:06:17.865959300Z"
    }
   },
   "id": "d4931d9e94624856",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "classes = d_train['species'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:17.958351Z",
     "start_time": "2024-03-22T22:06:17.869118100Z"
    }
   },
   "id": "98c4425f01e72d81",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(99,)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:17.959392200Z",
     "start_time": "2024-03-22T22:06:17.879952100Z"
    }
   },
   "id": "89ecbf4bddfdbc22",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Encoder les labels en numérique"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0de925cb135c094"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       id  species   margin1   margin2   margin3   margin4   margin5  \\\n0       1        3  0.007812  0.023438  0.023438  0.003906  0.011719   \n1       2       49  0.005859  0.000000  0.031250  0.015625  0.025391   \n2       3       65  0.005859  0.009766  0.019531  0.007812  0.003906   \n3       5       94  0.000000  0.003906  0.023438  0.005859  0.021484   \n4       6       84  0.005859  0.003906  0.048828  0.009766  0.013672   \n..    ...      ...       ...       ...       ...       ...       ...   \n985  1575       40  0.060547  0.119140  0.007812  0.003906  0.000000   \n986  1578        5  0.001953  0.003906  0.021484  0.107420  0.001953   \n987  1581       11  0.001953  0.003906  0.000000  0.021484  0.078125   \n988  1582       78  0.000000  0.000000  0.046875  0.056641  0.009766   \n989  1584       50  0.023438  0.019531  0.031250  0.015625  0.005859   \n\n      margin6   margin7  margin8  ...  texture55  texture56  texture57  \\\n0    0.009766  0.027344      0.0  ...   0.007812   0.000000   0.002930   \n1    0.001953  0.019531      0.0  ...   0.000977   0.000000   0.000000   \n2    0.005859  0.068359      0.0  ...   0.154300   0.000000   0.005859   \n3    0.019531  0.023438      0.0  ...   0.000000   0.000977   0.000000   \n4    0.015625  0.005859      0.0  ...   0.096680   0.000000   0.021484   \n..        ...       ...      ...  ...        ...        ...        ...   \n985  0.148440  0.017578      0.0  ...   0.242190   0.000000   0.034180   \n986  0.000000  0.000000      0.0  ...   0.170900   0.000000   0.018555   \n987  0.003906  0.007812      0.0  ...   0.004883   0.000977   0.004883   \n988  0.000000  0.000000      0.0  ...   0.083008   0.030273   0.000977   \n989  0.019531  0.035156      0.0  ...   0.000000   0.000000   0.002930   \n\n     texture58  texture59  texture60  texture61  texture62  texture63  \\\n0     0.002930   0.035156   0.000000   0.000000   0.004883   0.000000   \n1     0.000977   0.023438   0.000000   0.000000   0.000977   0.039062   \n2     0.000977   0.007812   0.000000   0.000000   0.000000   0.020508   \n3     0.000000   0.020508   0.000000   0.000000   0.017578   0.000000   \n4     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n..         ...        ...        ...        ...        ...        ...   \n985   0.000000   0.010742   0.000000   0.000000   0.000000   0.000000   \n986   0.000000   0.011719   0.000000   0.000000   0.000977   0.000000   \n987   0.027344   0.016602   0.007812   0.000000   0.027344   0.000000   \n988   0.002930   0.014648   0.000000   0.041992   0.000000   0.001953   \n989   0.000000   0.012695   0.000000   0.000000   0.023438   0.025391   \n\n     texture64  \n0     0.025391  \n1     0.022461  \n2     0.002930  \n3     0.047852  \n4     0.031250  \n..         ...  \n985   0.018555  \n986   0.021484  \n987   0.001953  \n988   0.002930  \n989   0.022461  \n\n[990 rows x 194 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>species</th>\n      <th>margin1</th>\n      <th>margin2</th>\n      <th>margin3</th>\n      <th>margin4</th>\n      <th>margin5</th>\n      <th>margin6</th>\n      <th>margin7</th>\n      <th>margin8</th>\n      <th>...</th>\n      <th>texture55</th>\n      <th>texture56</th>\n      <th>texture57</th>\n      <th>texture58</th>\n      <th>texture59</th>\n      <th>texture60</th>\n      <th>texture61</th>\n      <th>texture62</th>\n      <th>texture63</th>\n      <th>texture64</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.007812</td>\n      <td>0.023438</td>\n      <td>0.023438</td>\n      <td>0.003906</td>\n      <td>0.011719</td>\n      <td>0.009766</td>\n      <td>0.027344</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.007812</td>\n      <td>0.000000</td>\n      <td>0.002930</td>\n      <td>0.002930</td>\n      <td>0.035156</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.004883</td>\n      <td>0.000000</td>\n      <td>0.025391</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>49</td>\n      <td>0.005859</td>\n      <td>0.000000</td>\n      <td>0.031250</td>\n      <td>0.015625</td>\n      <td>0.025391</td>\n      <td>0.001953</td>\n      <td>0.019531</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000977</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000977</td>\n      <td>0.023438</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000977</td>\n      <td>0.039062</td>\n      <td>0.022461</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>65</td>\n      <td>0.005859</td>\n      <td>0.009766</td>\n      <td>0.019531</td>\n      <td>0.007812</td>\n      <td>0.003906</td>\n      <td>0.005859</td>\n      <td>0.068359</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.154300</td>\n      <td>0.000000</td>\n      <td>0.005859</td>\n      <td>0.000977</td>\n      <td>0.007812</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.020508</td>\n      <td>0.002930</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>94</td>\n      <td>0.000000</td>\n      <td>0.003906</td>\n      <td>0.023438</td>\n      <td>0.005859</td>\n      <td>0.021484</td>\n      <td>0.019531</td>\n      <td>0.023438</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000977</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.020508</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.017578</td>\n      <td>0.000000</td>\n      <td>0.047852</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>84</td>\n      <td>0.005859</td>\n      <td>0.003906</td>\n      <td>0.048828</td>\n      <td>0.009766</td>\n      <td>0.013672</td>\n      <td>0.015625</td>\n      <td>0.005859</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.096680</td>\n      <td>0.000000</td>\n      <td>0.021484</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.031250</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>985</th>\n      <td>1575</td>\n      <td>40</td>\n      <td>0.060547</td>\n      <td>0.119140</td>\n      <td>0.007812</td>\n      <td>0.003906</td>\n      <td>0.000000</td>\n      <td>0.148440</td>\n      <td>0.017578</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.242190</td>\n      <td>0.000000</td>\n      <td>0.034180</td>\n      <td>0.000000</td>\n      <td>0.010742</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.018555</td>\n    </tr>\n    <tr>\n      <th>986</th>\n      <td>1578</td>\n      <td>5</td>\n      <td>0.001953</td>\n      <td>0.003906</td>\n      <td>0.021484</td>\n      <td>0.107420</td>\n      <td>0.001953</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.170900</td>\n      <td>0.000000</td>\n      <td>0.018555</td>\n      <td>0.000000</td>\n      <td>0.011719</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000977</td>\n      <td>0.000000</td>\n      <td>0.021484</td>\n    </tr>\n    <tr>\n      <th>987</th>\n      <td>1581</td>\n      <td>11</td>\n      <td>0.001953</td>\n      <td>0.003906</td>\n      <td>0.000000</td>\n      <td>0.021484</td>\n      <td>0.078125</td>\n      <td>0.003906</td>\n      <td>0.007812</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.004883</td>\n      <td>0.000977</td>\n      <td>0.004883</td>\n      <td>0.027344</td>\n      <td>0.016602</td>\n      <td>0.007812</td>\n      <td>0.000000</td>\n      <td>0.027344</td>\n      <td>0.000000</td>\n      <td>0.001953</td>\n    </tr>\n    <tr>\n      <th>988</th>\n      <td>1582</td>\n      <td>78</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.046875</td>\n      <td>0.056641</td>\n      <td>0.009766</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.083008</td>\n      <td>0.030273</td>\n      <td>0.000977</td>\n      <td>0.002930</td>\n      <td>0.014648</td>\n      <td>0.000000</td>\n      <td>0.041992</td>\n      <td>0.000000</td>\n      <td>0.001953</td>\n      <td>0.002930</td>\n    </tr>\n    <tr>\n      <th>989</th>\n      <td>1584</td>\n      <td>50</td>\n      <td>0.023438</td>\n      <td>0.019531</td>\n      <td>0.031250</td>\n      <td>0.015625</td>\n      <td>0.005859</td>\n      <td>0.019531</td>\n      <td>0.035156</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002930</td>\n      <td>0.000000</td>\n      <td>0.012695</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.023438</td>\n      <td>0.025391</td>\n      <td>0.022461</td>\n    </tr>\n  </tbody>\n</table>\n<p>990 rows × 194 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = d_train.copy() # copy \n",
    "processed_test_data = d_test.copy() # test data n'ont pas des labels\n",
    "# Initialize the encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode the 'species' column\n",
    "processed_data['species'] = le.fit_transform(processed_data['species']) # encoder species\n",
    "\n",
    "processed_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:18.003340100Z",
     "start_time": "2024-03-22T22:06:17.886092500Z"
    }
   },
   "id": "fb1563ff72ff60bf",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mise à l'échelle\n",
    "La mise à l'échelle des données, ou normalisation, est une étape cruciale en prétraitement des données. le but :\n",
    "\n",
    "\n",
    "1. **Uniformité**: Elle assure que toutes les caractéristiques numériques contribuent également à l'analyse sans être biaisées par leur échelle d'origine.\n",
    "\n",
    "2. **Meilleure convergence**: Beaucoup d'algorithmes de machine learning, comme les réseaux de neurones et les méthodes de descente de gradient, convergent plus rapidement lorsque les données sont mises à l'échelle.\n",
    "\n",
    "3. **Amélioration des performances**: Certains algorithmes, en particulier ceux qui utilisent des mesures de distance comme k-means ou k-NN, ont de meilleures performances si toutes les caractéristiques sont sur une échelle comparable.\n",
    "\n",
    "4. **Stabilité numérique**: La mise à l'échelle peut aussi aider à éviter des problèmes numériques qui peuvent survenir lorsque les caractéristiques ont des ordres de grandeur très différents.\n",
    "\n",
    "En somme, la mise à l'échelle des données aide à rendre le processus d'apprentissage automatique plus efficace et plus stable."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b3f467d46c7e537"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c21d77ac7887646f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       id   margin1   margin2   margin3   margin4   margin5   margin6  \\\n0       4  0.227268  0.051549  0.465113  0.071431  0.041664  0.057555   \n1       7  0.090903  0.030926  0.383717  0.059527  0.041664  0.050361   \n2       9  0.000000  0.000000  0.011627  0.130952  0.437504  0.000000   \n3      12  0.000000  0.000000  0.058141  0.071431  0.187499  0.000000   \n4      13  0.022726  0.000000  0.093023  0.059527  0.416661  0.000000   \n..    ...       ...       ...       ...       ...       ...       ...   \n589  1576  0.000000  0.000000  0.023254  0.095240  0.437504  0.000000   \n590  1577  0.000000  0.020618  0.023254  0.035713  0.187499  0.000000   \n591  1579  0.204543  0.154642  0.093023  0.083335  0.041664  0.057555   \n592  1580  0.159091  0.051549  0.360463  0.154767  0.374997  0.093528   \n593  1583  0.000000  0.618580  0.000000  0.119048  0.000000  0.503610   \n\n      margin7   margin8   margin9  ...  texture55  texture56  texture57  \\\n0    0.066662  0.000000  0.069763  ...   0.019337   0.000000   0.101911   \n1    0.088883  0.000000  0.395349  ...   0.000000   0.000000   0.044586   \n2    0.266671  0.000000  0.139538  ...   0.364647   0.000000   0.006372   \n3    0.044441  0.000000  0.046509  ...   0.035910   0.035398   0.019110   \n4    0.111115  0.000000  0.069763  ...   0.000000   0.097345   0.108283   \n..        ...       ...       ...  ...        ...        ...        ...   \n589  0.199998  0.000000  0.069763  ...   0.279003   0.000000   0.031848   \n590  0.199998  0.272715  0.000000  ...   0.035910   0.011062   0.031848   \n591  0.288892  0.000000  0.000000  ...   0.207179   0.000000   0.184712   \n592  0.444437  0.000000  0.046509  ...   0.011049   0.000000   0.006372   \n593  0.022221  0.272715  0.000000  ...   0.303858   0.028760   0.108283   \n\n     texture58  texture59  texture60  texture61  texture62  texture63  \\\n0     0.005497   0.186047        0.0        0.0   0.000000   0.044941   \n1     0.010989   0.162793        0.0        0.0   0.003954   0.426962   \n2     0.000000   0.000000        0.0        0.0   0.063241   0.000000   \n3     0.203303   0.162793        0.0        0.0   0.363638   0.000000   \n4     0.060440   0.488379        0.0        0.0   0.031619   0.112364   \n..         ...        ...        ...        ...        ...        ...   \n589   0.000000   0.046509        0.0        0.0   0.075100   0.000000   \n590   0.016486   0.116284        0.0        0.0   0.367588   0.000000   \n591   0.000000   0.023254        0.0        0.0   0.000000   0.494385   \n592   0.000000   0.139538        0.0        0.0   0.000000   0.134834   \n593   0.005497   0.058142        0.0        0.0   0.063241   0.000000   \n\n     texture64  \n0     0.359487  \n1     0.300663  \n2     0.000000  \n3     0.058825  \n4     0.052286  \n..         ...  \n589   0.006539  \n590   0.111117  \n591   0.045753  \n592   0.124188  \n593   0.117649  \n\n[594 rows x 193 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>margin1</th>\n      <th>margin2</th>\n      <th>margin3</th>\n      <th>margin4</th>\n      <th>margin5</th>\n      <th>margin6</th>\n      <th>margin7</th>\n      <th>margin8</th>\n      <th>margin9</th>\n      <th>...</th>\n      <th>texture55</th>\n      <th>texture56</th>\n      <th>texture57</th>\n      <th>texture58</th>\n      <th>texture59</th>\n      <th>texture60</th>\n      <th>texture61</th>\n      <th>texture62</th>\n      <th>texture63</th>\n      <th>texture64</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>0.227268</td>\n      <td>0.051549</td>\n      <td>0.465113</td>\n      <td>0.071431</td>\n      <td>0.041664</td>\n      <td>0.057555</td>\n      <td>0.066662</td>\n      <td>0.000000</td>\n      <td>0.069763</td>\n      <td>...</td>\n      <td>0.019337</td>\n      <td>0.000000</td>\n      <td>0.101911</td>\n      <td>0.005497</td>\n      <td>0.186047</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.044941</td>\n      <td>0.359487</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>0.090903</td>\n      <td>0.030926</td>\n      <td>0.383717</td>\n      <td>0.059527</td>\n      <td>0.041664</td>\n      <td>0.050361</td>\n      <td>0.088883</td>\n      <td>0.000000</td>\n      <td>0.395349</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.044586</td>\n      <td>0.010989</td>\n      <td>0.162793</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.003954</td>\n      <td>0.426962</td>\n      <td>0.300663</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.011627</td>\n      <td>0.130952</td>\n      <td>0.437504</td>\n      <td>0.000000</td>\n      <td>0.266671</td>\n      <td>0.000000</td>\n      <td>0.139538</td>\n      <td>...</td>\n      <td>0.364647</td>\n      <td>0.000000</td>\n      <td>0.006372</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.063241</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.058141</td>\n      <td>0.071431</td>\n      <td>0.187499</td>\n      <td>0.000000</td>\n      <td>0.044441</td>\n      <td>0.000000</td>\n      <td>0.046509</td>\n      <td>...</td>\n      <td>0.035910</td>\n      <td>0.035398</td>\n      <td>0.019110</td>\n      <td>0.203303</td>\n      <td>0.162793</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.363638</td>\n      <td>0.000000</td>\n      <td>0.058825</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13</td>\n      <td>0.022726</td>\n      <td>0.000000</td>\n      <td>0.093023</td>\n      <td>0.059527</td>\n      <td>0.416661</td>\n      <td>0.000000</td>\n      <td>0.111115</td>\n      <td>0.000000</td>\n      <td>0.069763</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.097345</td>\n      <td>0.108283</td>\n      <td>0.060440</td>\n      <td>0.488379</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.031619</td>\n      <td>0.112364</td>\n      <td>0.052286</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>589</th>\n      <td>1576</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.023254</td>\n      <td>0.095240</td>\n      <td>0.437504</td>\n      <td>0.000000</td>\n      <td>0.199998</td>\n      <td>0.000000</td>\n      <td>0.069763</td>\n      <td>...</td>\n      <td>0.279003</td>\n      <td>0.000000</td>\n      <td>0.031848</td>\n      <td>0.000000</td>\n      <td>0.046509</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.075100</td>\n      <td>0.000000</td>\n      <td>0.006539</td>\n    </tr>\n    <tr>\n      <th>590</th>\n      <td>1577</td>\n      <td>0.000000</td>\n      <td>0.020618</td>\n      <td>0.023254</td>\n      <td>0.035713</td>\n      <td>0.187499</td>\n      <td>0.000000</td>\n      <td>0.199998</td>\n      <td>0.272715</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.035910</td>\n      <td>0.011062</td>\n      <td>0.031848</td>\n      <td>0.016486</td>\n      <td>0.116284</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.367588</td>\n      <td>0.000000</td>\n      <td>0.111117</td>\n    </tr>\n    <tr>\n      <th>591</th>\n      <td>1579</td>\n      <td>0.204543</td>\n      <td>0.154642</td>\n      <td>0.093023</td>\n      <td>0.083335</td>\n      <td>0.041664</td>\n      <td>0.057555</td>\n      <td>0.288892</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.207179</td>\n      <td>0.000000</td>\n      <td>0.184712</td>\n      <td>0.000000</td>\n      <td>0.023254</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.494385</td>\n      <td>0.045753</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>1580</td>\n      <td>0.159091</td>\n      <td>0.051549</td>\n      <td>0.360463</td>\n      <td>0.154767</td>\n      <td>0.374997</td>\n      <td>0.093528</td>\n      <td>0.444437</td>\n      <td>0.000000</td>\n      <td>0.046509</td>\n      <td>...</td>\n      <td>0.011049</td>\n      <td>0.000000</td>\n      <td>0.006372</td>\n      <td>0.000000</td>\n      <td>0.139538</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.134834</td>\n      <td>0.124188</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>1583</td>\n      <td>0.000000</td>\n      <td>0.618580</td>\n      <td>0.000000</td>\n      <td>0.119048</td>\n      <td>0.000000</td>\n      <td>0.503610</td>\n      <td>0.022221</td>\n      <td>0.272715</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.303858</td>\n      <td>0.028760</td>\n      <td>0.108283</td>\n      <td>0.005497</td>\n      <td>0.058142</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.063241</td>\n      <td>0.000000</td>\n      <td>0.117649</td>\n    </tr>\n  </tbody>\n</table>\n<p>594 rows × 193 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "# test data\n",
    "# Scale numeric columns. Exclude 'id' and 'species' from being scaled\n",
    "numeric_cols = processed_test_data.columns.drop(['id'])\n",
    "processed_test_data[numeric_cols] = scaler.fit_transform(processed_test_data[numeric_cols])\n",
    "processed_test_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:18.026692500Z",
     "start_time": "2024-03-22T22:06:17.937464700Z"
    }
   },
   "id": "df9807ecef0f0ddd",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94e6a0a59ddf93d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       id  species   margin1   margin2   margin3   margin4   margin5  \\\n0       1        3  0.088883  0.114287  0.150003  0.022987  0.105264   \n1       2       49  0.066662  0.000000  0.200000  0.091955  0.228070   \n2       3       65  0.066662  0.047620  0.124998  0.045975  0.035085   \n3       5       94  0.000000  0.019046  0.150003  0.034481  0.192976   \n4       6       84  0.066662  0.019046  0.312499  0.057474  0.122806   \n..    ...      ...       ...       ...       ...       ...       ...   \n985  1575       40  0.688887  0.580944  0.049997  0.022987  0.000000   \n986  1578        5  0.022221  0.019046  0.137498  0.632180  0.017542   \n987  1581       11  0.022221  0.019046  0.000000  0.126436  0.701743   \n988  1582       78  0.000000  0.000000  0.300000  0.333339  0.087721   \n989  1584       50  0.266671  0.095236  0.200000  0.091955  0.052627   \n\n      margin6   margin7  margin8  ...  texture55  texture56  texture57  \\\n0    0.031447  0.297875      0.0  ...   0.018181   0.000000   0.016951   \n1    0.006289  0.212763      0.0  ...   0.002274   0.000000   0.000000   \n2    0.018867  0.744676      0.0  ...   0.359096   0.000000   0.033896   \n3    0.062892  0.255324      0.0  ...   0.000000   0.004833   0.000000   \n4    0.050314  0.063826      0.0  ...   0.224999   0.000000   0.124293   \n..        ...       ...      ...  ...        ...        ...        ...   \n985  0.477991  0.191488      0.0  ...   0.563639   0.000000   0.197744   \n986  0.000000  0.000000      0.0  ...   0.397729   0.000000   0.107347   \n987  0.012578  0.085101      0.0  ...   0.011364   0.004833   0.028250   \n988  0.000000  0.000000      0.0  ...   0.193181   0.149755   0.005652   \n989  0.062892  0.382975      0.0  ...   0.000000   0.000000   0.016951   \n\n     texture58  texture59  texture60  texture61  texture62  texture63  \\\n0     0.014635   0.330258   0.000000   0.000000   0.012987   0.000000   \n1     0.004880   0.220178   0.000000   0.000000   0.002599   0.449433   \n2     0.004880   0.073387   0.000000   0.000000   0.000000   0.235957   \n3     0.000000   0.192654   0.000000   0.000000   0.046752   0.000000   \n4     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n..         ...        ...        ...        ...        ...        ...   \n985   0.000000   0.100911   0.000000   0.000000   0.000000   0.000000   \n986   0.000000   0.110089   0.000000   0.000000   0.002599   0.000000   \n987   0.136583   0.155961   0.013513   0.000000   0.072727   0.000000   \n988   0.014635   0.137605   0.000000   0.277413   0.000000   0.022470   \n989   0.000000   0.119258   0.000000   0.000000   0.062338   0.292139   \n\n     texture64  \n0     0.179315  \n1     0.158623  \n2     0.020692  \n3     0.337938  \n4     0.220692  \n..         ...  \n985   0.131038  \n986   0.151723  \n987   0.013792  \n988   0.020692  \n989   0.158623  \n\n[990 rows x 194 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>species</th>\n      <th>margin1</th>\n      <th>margin2</th>\n      <th>margin3</th>\n      <th>margin4</th>\n      <th>margin5</th>\n      <th>margin6</th>\n      <th>margin7</th>\n      <th>margin8</th>\n      <th>...</th>\n      <th>texture55</th>\n      <th>texture56</th>\n      <th>texture57</th>\n      <th>texture58</th>\n      <th>texture59</th>\n      <th>texture60</th>\n      <th>texture61</th>\n      <th>texture62</th>\n      <th>texture63</th>\n      <th>texture64</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.088883</td>\n      <td>0.114287</td>\n      <td>0.150003</td>\n      <td>0.022987</td>\n      <td>0.105264</td>\n      <td>0.031447</td>\n      <td>0.297875</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.018181</td>\n      <td>0.000000</td>\n      <td>0.016951</td>\n      <td>0.014635</td>\n      <td>0.330258</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.012987</td>\n      <td>0.000000</td>\n      <td>0.179315</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>49</td>\n      <td>0.066662</td>\n      <td>0.000000</td>\n      <td>0.200000</td>\n      <td>0.091955</td>\n      <td>0.228070</td>\n      <td>0.006289</td>\n      <td>0.212763</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.002274</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.004880</td>\n      <td>0.220178</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002599</td>\n      <td>0.449433</td>\n      <td>0.158623</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>65</td>\n      <td>0.066662</td>\n      <td>0.047620</td>\n      <td>0.124998</td>\n      <td>0.045975</td>\n      <td>0.035085</td>\n      <td>0.018867</td>\n      <td>0.744676</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.359096</td>\n      <td>0.000000</td>\n      <td>0.033896</td>\n      <td>0.004880</td>\n      <td>0.073387</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.235957</td>\n      <td>0.020692</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>94</td>\n      <td>0.000000</td>\n      <td>0.019046</td>\n      <td>0.150003</td>\n      <td>0.034481</td>\n      <td>0.192976</td>\n      <td>0.062892</td>\n      <td>0.255324</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.004833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.192654</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.046752</td>\n      <td>0.000000</td>\n      <td>0.337938</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>84</td>\n      <td>0.066662</td>\n      <td>0.019046</td>\n      <td>0.312499</td>\n      <td>0.057474</td>\n      <td>0.122806</td>\n      <td>0.050314</td>\n      <td>0.063826</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.224999</td>\n      <td>0.000000</td>\n      <td>0.124293</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.220692</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>985</th>\n      <td>1575</td>\n      <td>40</td>\n      <td>0.688887</td>\n      <td>0.580944</td>\n      <td>0.049997</td>\n      <td>0.022987</td>\n      <td>0.000000</td>\n      <td>0.477991</td>\n      <td>0.191488</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.563639</td>\n      <td>0.000000</td>\n      <td>0.197744</td>\n      <td>0.000000</td>\n      <td>0.100911</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.131038</td>\n    </tr>\n    <tr>\n      <th>986</th>\n      <td>1578</td>\n      <td>5</td>\n      <td>0.022221</td>\n      <td>0.019046</td>\n      <td>0.137498</td>\n      <td>0.632180</td>\n      <td>0.017542</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.397729</td>\n      <td>0.000000</td>\n      <td>0.107347</td>\n      <td>0.000000</td>\n      <td>0.110089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002599</td>\n      <td>0.000000</td>\n      <td>0.151723</td>\n    </tr>\n    <tr>\n      <th>987</th>\n      <td>1581</td>\n      <td>11</td>\n      <td>0.022221</td>\n      <td>0.019046</td>\n      <td>0.000000</td>\n      <td>0.126436</td>\n      <td>0.701743</td>\n      <td>0.012578</td>\n      <td>0.085101</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.011364</td>\n      <td>0.004833</td>\n      <td>0.028250</td>\n      <td>0.136583</td>\n      <td>0.155961</td>\n      <td>0.013513</td>\n      <td>0.000000</td>\n      <td>0.072727</td>\n      <td>0.000000</td>\n      <td>0.013792</td>\n    </tr>\n    <tr>\n      <th>988</th>\n      <td>1582</td>\n      <td>78</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.300000</td>\n      <td>0.333339</td>\n      <td>0.087721</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.193181</td>\n      <td>0.149755</td>\n      <td>0.005652</td>\n      <td>0.014635</td>\n      <td>0.137605</td>\n      <td>0.000000</td>\n      <td>0.277413</td>\n      <td>0.000000</td>\n      <td>0.022470</td>\n      <td>0.020692</td>\n    </tr>\n    <tr>\n      <th>989</th>\n      <td>1584</td>\n      <td>50</td>\n      <td>0.266671</td>\n      <td>0.095236</td>\n      <td>0.200000</td>\n      <td>0.091955</td>\n      <td>0.052627</td>\n      <td>0.062892</td>\n      <td>0.382975</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.016951</td>\n      <td>0.000000</td>\n      <td>0.119258</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.062338</td>\n      <td>0.292139</td>\n      <td>0.158623</td>\n    </tr>\n  </tbody>\n</table>\n<p>990 rows × 194 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# train data\n",
    "# Scale numeric columns. Exclude 'id' and 'species' from being scaled\n",
    "numeric_cols = processed_data.columns.drop(['id', 'species'])\n",
    "processed_data[numeric_cols] = scaler.fit_transform(processed_data[numeric_cols])\n",
    "processed_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:18.072383600Z",
     "start_time": "2024-03-22T22:06:17.982006800Z"
    }
   },
   "id": "3c1d6cfb1c064b54",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n0    0.088883  0.114287  0.150003  0.022987  0.105264  0.031447  0.297875   \n1    0.066662  0.000000  0.200000  0.091955  0.228070  0.006289  0.212763   \n2    0.066662  0.047620  0.124998  0.045975  0.035085  0.018867  0.744676   \n3    0.000000  0.019046  0.150003  0.034481  0.192976  0.062892  0.255324   \n4    0.066662  0.019046  0.312499  0.057474  0.122806  0.050314  0.063826   \n..        ...       ...       ...       ...       ...       ...       ...   \n985  0.688887  0.580944  0.049997  0.022987  0.000000  0.477991  0.191488   \n986  0.022221  0.019046  0.137498  0.632180  0.017542  0.000000  0.000000   \n987  0.022221  0.019046  0.000000  0.126436  0.701743  0.012578  0.085101   \n988  0.000000  0.000000  0.300000  0.333339  0.087721  0.000000  0.000000   \n989  0.266671  0.095236  0.200000  0.091955  0.052627  0.062892  0.382975   \n\n     margin8   margin9  margin10  ...  texture55  texture56  texture57  \\\n0        0.0  0.025639  0.340000  ...   0.018181   0.000000   0.016951   \n1        0.0  0.000000  0.079995  ...   0.002274   0.000000   0.000000   \n2        0.0  0.000000  0.460002  ...   0.359096   0.000000   0.033896   \n3        0.0  0.179489  0.179999  ...   0.000000   0.004833   0.000000   \n4        0.0  0.000000  0.059996  ...   0.224999   0.000000   0.124293   \n..       ...       ...       ...  ...        ...        ...        ...   \n985      0.0  0.025639  0.440004  ...   0.563639   0.000000   0.197744   \n986      0.0  0.384616  0.039998  ...   0.397729   0.000000   0.107347   \n987      0.0  0.051279  0.000000  ...   0.011364   0.004833   0.028250   \n988      0.0  0.487174  0.019999  ...   0.193181   0.149755   0.005652   \n989      0.0  0.051279  0.399996  ...   0.000000   0.000000   0.016951   \n\n     texture58  texture59  texture60  texture61  texture62  texture63  \\\n0     0.014635   0.330258   0.000000   0.000000   0.012987   0.000000   \n1     0.004880   0.220178   0.000000   0.000000   0.002599   0.449433   \n2     0.004880   0.073387   0.000000   0.000000   0.000000   0.235957   \n3     0.000000   0.192654   0.000000   0.000000   0.046752   0.000000   \n4     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n..         ...        ...        ...        ...        ...        ...   \n985   0.000000   0.100911   0.000000   0.000000   0.000000   0.000000   \n986   0.000000   0.110089   0.000000   0.000000   0.002599   0.000000   \n987   0.136583   0.155961   0.013513   0.000000   0.072727   0.000000   \n988   0.014635   0.137605   0.000000   0.277413   0.000000   0.022470   \n989   0.000000   0.119258   0.000000   0.000000   0.062338   0.292139   \n\n     texture64  \n0     0.179315  \n1     0.158623  \n2     0.020692  \n3     0.337938  \n4     0.220692  \n..         ...  \n985   0.131038  \n986   0.151723  \n987   0.013792  \n988   0.020692  \n989   0.158623  \n\n[990 rows x 192 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>margin1</th>\n      <th>margin2</th>\n      <th>margin3</th>\n      <th>margin4</th>\n      <th>margin5</th>\n      <th>margin6</th>\n      <th>margin7</th>\n      <th>margin8</th>\n      <th>margin9</th>\n      <th>margin10</th>\n      <th>...</th>\n      <th>texture55</th>\n      <th>texture56</th>\n      <th>texture57</th>\n      <th>texture58</th>\n      <th>texture59</th>\n      <th>texture60</th>\n      <th>texture61</th>\n      <th>texture62</th>\n      <th>texture63</th>\n      <th>texture64</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.088883</td>\n      <td>0.114287</td>\n      <td>0.150003</td>\n      <td>0.022987</td>\n      <td>0.105264</td>\n      <td>0.031447</td>\n      <td>0.297875</td>\n      <td>0.0</td>\n      <td>0.025639</td>\n      <td>0.340000</td>\n      <td>...</td>\n      <td>0.018181</td>\n      <td>0.000000</td>\n      <td>0.016951</td>\n      <td>0.014635</td>\n      <td>0.330258</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.012987</td>\n      <td>0.000000</td>\n      <td>0.179315</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.066662</td>\n      <td>0.000000</td>\n      <td>0.200000</td>\n      <td>0.091955</td>\n      <td>0.228070</td>\n      <td>0.006289</td>\n      <td>0.212763</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.079995</td>\n      <td>...</td>\n      <td>0.002274</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.004880</td>\n      <td>0.220178</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002599</td>\n      <td>0.449433</td>\n      <td>0.158623</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.066662</td>\n      <td>0.047620</td>\n      <td>0.124998</td>\n      <td>0.045975</td>\n      <td>0.035085</td>\n      <td>0.018867</td>\n      <td>0.744676</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.460002</td>\n      <td>...</td>\n      <td>0.359096</td>\n      <td>0.000000</td>\n      <td>0.033896</td>\n      <td>0.004880</td>\n      <td>0.073387</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.235957</td>\n      <td>0.020692</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.019046</td>\n      <td>0.150003</td>\n      <td>0.034481</td>\n      <td>0.192976</td>\n      <td>0.062892</td>\n      <td>0.255324</td>\n      <td>0.0</td>\n      <td>0.179489</td>\n      <td>0.179999</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.004833</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.192654</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.046752</td>\n      <td>0.000000</td>\n      <td>0.337938</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.066662</td>\n      <td>0.019046</td>\n      <td>0.312499</td>\n      <td>0.057474</td>\n      <td>0.122806</td>\n      <td>0.050314</td>\n      <td>0.063826</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.059996</td>\n      <td>...</td>\n      <td>0.224999</td>\n      <td>0.000000</td>\n      <td>0.124293</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.220692</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>985</th>\n      <td>0.688887</td>\n      <td>0.580944</td>\n      <td>0.049997</td>\n      <td>0.022987</td>\n      <td>0.000000</td>\n      <td>0.477991</td>\n      <td>0.191488</td>\n      <td>0.0</td>\n      <td>0.025639</td>\n      <td>0.440004</td>\n      <td>...</td>\n      <td>0.563639</td>\n      <td>0.000000</td>\n      <td>0.197744</td>\n      <td>0.000000</td>\n      <td>0.100911</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.131038</td>\n    </tr>\n    <tr>\n      <th>986</th>\n      <td>0.022221</td>\n      <td>0.019046</td>\n      <td>0.137498</td>\n      <td>0.632180</td>\n      <td>0.017542</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.384616</td>\n      <td>0.039998</td>\n      <td>...</td>\n      <td>0.397729</td>\n      <td>0.000000</td>\n      <td>0.107347</td>\n      <td>0.000000</td>\n      <td>0.110089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002599</td>\n      <td>0.000000</td>\n      <td>0.151723</td>\n    </tr>\n    <tr>\n      <th>987</th>\n      <td>0.022221</td>\n      <td>0.019046</td>\n      <td>0.000000</td>\n      <td>0.126436</td>\n      <td>0.701743</td>\n      <td>0.012578</td>\n      <td>0.085101</td>\n      <td>0.0</td>\n      <td>0.051279</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.011364</td>\n      <td>0.004833</td>\n      <td>0.028250</td>\n      <td>0.136583</td>\n      <td>0.155961</td>\n      <td>0.013513</td>\n      <td>0.000000</td>\n      <td>0.072727</td>\n      <td>0.000000</td>\n      <td>0.013792</td>\n    </tr>\n    <tr>\n      <th>988</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.300000</td>\n      <td>0.333339</td>\n      <td>0.087721</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.487174</td>\n      <td>0.019999</td>\n      <td>...</td>\n      <td>0.193181</td>\n      <td>0.149755</td>\n      <td>0.005652</td>\n      <td>0.014635</td>\n      <td>0.137605</td>\n      <td>0.000000</td>\n      <td>0.277413</td>\n      <td>0.000000</td>\n      <td>0.022470</td>\n      <td>0.020692</td>\n    </tr>\n    <tr>\n      <th>989</th>\n      <td>0.266671</td>\n      <td>0.095236</td>\n      <td>0.200000</td>\n      <td>0.091955</td>\n      <td>0.052627</td>\n      <td>0.062892</td>\n      <td>0.382975</td>\n      <td>0.0</td>\n      <td>0.051279</td>\n      <td>0.399996</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.016951</td>\n      <td>0.000000</td>\n      <td>0.119258</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.062338</td>\n      <td>0.292139</td>\n      <td>0.158623</td>\n    </tr>\n  </tbody>\n</table>\n<p>990 rows × 192 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = processed_data.drop(columns=['id', 'species'])\n",
    "x_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:18.146424200Z",
     "start_time": "2024-03-22T22:06:18.031372600Z"
    }
   },
   "id": "f1c0fd1bf84c98ae",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0       3\n1      49\n2      65\n3      94\n4      84\n       ..\n985    40\n986     5\n987    11\n988    78\n989    50\nName: species, Length: 990, dtype: int32"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = processed_data['species']\n",
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:18.181714Z",
     "start_time": "2024-03-22T22:06:18.062745Z"
    }
   },
   "id": "808be255ca5b1f43",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n0    0.227268  0.051549  0.465113  0.071431  0.041664  0.057555  0.066662   \n1    0.090903  0.030926  0.383717  0.059527  0.041664  0.050361  0.088883   \n2    0.000000  0.000000  0.011627  0.130952  0.437504  0.000000  0.266671   \n3    0.000000  0.000000  0.058141  0.071431  0.187499  0.000000  0.044441   \n4    0.022726  0.000000  0.093023  0.059527  0.416661  0.000000  0.111115   \n..        ...       ...       ...       ...       ...       ...       ...   \n589  0.000000  0.000000  0.023254  0.095240  0.437504  0.000000  0.199998   \n590  0.000000  0.020618  0.023254  0.035713  0.187499  0.000000  0.199998   \n591  0.204543  0.154642  0.093023  0.083335  0.041664  0.057555  0.288892   \n592  0.159091  0.051549  0.360463  0.154767  0.374997  0.093528  0.444437   \n593  0.000000  0.618580  0.000000  0.119048  0.000000  0.503610  0.022221   \n\n      margin8   margin9  margin10  ...  texture55  texture56  texture57  \\\n0    0.000000  0.069763  0.279077  ...   0.019337   0.000000   0.101911   \n1    0.000000  0.395349  0.279077  ...   0.000000   0.000000   0.044586   \n2    0.000000  0.139538  0.069763  ...   0.364647   0.000000   0.006372   \n3    0.000000  0.046509  0.023254  ...   0.035910   0.035398   0.019110   \n4    0.000000  0.069763  0.000000  ...   0.000000   0.097345   0.108283   \n..        ...       ...       ...  ...        ...        ...        ...   \n589  0.000000  0.069763  0.162793  ...   0.279003   0.000000   0.031848   \n590  0.272715  0.000000  0.069763  ...   0.035910   0.011062   0.031848   \n591  0.000000  0.000000  0.116284  ...   0.207179   0.000000   0.184712   \n592  0.000000  0.046509  0.279077  ...   0.011049   0.000000   0.006372   \n593  0.272715  0.000000  0.093018  ...   0.303858   0.028760   0.108283   \n\n     texture58  texture59  texture60  texture61  texture62  texture63  \\\n0     0.005497   0.186047        0.0        0.0   0.000000   0.044941   \n1     0.010989   0.162793        0.0        0.0   0.003954   0.426962   \n2     0.000000   0.000000        0.0        0.0   0.063241   0.000000   \n3     0.203303   0.162793        0.0        0.0   0.363638   0.000000   \n4     0.060440   0.488379        0.0        0.0   0.031619   0.112364   \n..         ...        ...        ...        ...        ...        ...   \n589   0.000000   0.046509        0.0        0.0   0.075100   0.000000   \n590   0.016486   0.116284        0.0        0.0   0.367588   0.000000   \n591   0.000000   0.023254        0.0        0.0   0.000000   0.494385   \n592   0.000000   0.139538        0.0        0.0   0.000000   0.134834   \n593   0.005497   0.058142        0.0        0.0   0.063241   0.000000   \n\n     texture64  \n0     0.359487  \n1     0.300663  \n2     0.000000  \n3     0.058825  \n4     0.052286  \n..         ...  \n589   0.006539  \n590   0.111117  \n591   0.045753  \n592   0.124188  \n593   0.117649  \n\n[594 rows x 192 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>margin1</th>\n      <th>margin2</th>\n      <th>margin3</th>\n      <th>margin4</th>\n      <th>margin5</th>\n      <th>margin6</th>\n      <th>margin7</th>\n      <th>margin8</th>\n      <th>margin9</th>\n      <th>margin10</th>\n      <th>...</th>\n      <th>texture55</th>\n      <th>texture56</th>\n      <th>texture57</th>\n      <th>texture58</th>\n      <th>texture59</th>\n      <th>texture60</th>\n      <th>texture61</th>\n      <th>texture62</th>\n      <th>texture63</th>\n      <th>texture64</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.227268</td>\n      <td>0.051549</td>\n      <td>0.465113</td>\n      <td>0.071431</td>\n      <td>0.041664</td>\n      <td>0.057555</td>\n      <td>0.066662</td>\n      <td>0.000000</td>\n      <td>0.069763</td>\n      <td>0.279077</td>\n      <td>...</td>\n      <td>0.019337</td>\n      <td>0.000000</td>\n      <td>0.101911</td>\n      <td>0.005497</td>\n      <td>0.186047</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.044941</td>\n      <td>0.359487</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.090903</td>\n      <td>0.030926</td>\n      <td>0.383717</td>\n      <td>0.059527</td>\n      <td>0.041664</td>\n      <td>0.050361</td>\n      <td>0.088883</td>\n      <td>0.000000</td>\n      <td>0.395349</td>\n      <td>0.279077</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.044586</td>\n      <td>0.010989</td>\n      <td>0.162793</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.003954</td>\n      <td>0.426962</td>\n      <td>0.300663</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.011627</td>\n      <td>0.130952</td>\n      <td>0.437504</td>\n      <td>0.000000</td>\n      <td>0.266671</td>\n      <td>0.000000</td>\n      <td>0.139538</td>\n      <td>0.069763</td>\n      <td>...</td>\n      <td>0.364647</td>\n      <td>0.000000</td>\n      <td>0.006372</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.063241</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.058141</td>\n      <td>0.071431</td>\n      <td>0.187499</td>\n      <td>0.000000</td>\n      <td>0.044441</td>\n      <td>0.000000</td>\n      <td>0.046509</td>\n      <td>0.023254</td>\n      <td>...</td>\n      <td>0.035910</td>\n      <td>0.035398</td>\n      <td>0.019110</td>\n      <td>0.203303</td>\n      <td>0.162793</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.363638</td>\n      <td>0.000000</td>\n      <td>0.058825</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.022726</td>\n      <td>0.000000</td>\n      <td>0.093023</td>\n      <td>0.059527</td>\n      <td>0.416661</td>\n      <td>0.000000</td>\n      <td>0.111115</td>\n      <td>0.000000</td>\n      <td>0.069763</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.097345</td>\n      <td>0.108283</td>\n      <td>0.060440</td>\n      <td>0.488379</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.031619</td>\n      <td>0.112364</td>\n      <td>0.052286</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>589</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.023254</td>\n      <td>0.095240</td>\n      <td>0.437504</td>\n      <td>0.000000</td>\n      <td>0.199998</td>\n      <td>0.000000</td>\n      <td>0.069763</td>\n      <td>0.162793</td>\n      <td>...</td>\n      <td>0.279003</td>\n      <td>0.000000</td>\n      <td>0.031848</td>\n      <td>0.000000</td>\n      <td>0.046509</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.075100</td>\n      <td>0.000000</td>\n      <td>0.006539</td>\n    </tr>\n    <tr>\n      <th>590</th>\n      <td>0.000000</td>\n      <td>0.020618</td>\n      <td>0.023254</td>\n      <td>0.035713</td>\n      <td>0.187499</td>\n      <td>0.000000</td>\n      <td>0.199998</td>\n      <td>0.272715</td>\n      <td>0.000000</td>\n      <td>0.069763</td>\n      <td>...</td>\n      <td>0.035910</td>\n      <td>0.011062</td>\n      <td>0.031848</td>\n      <td>0.016486</td>\n      <td>0.116284</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.367588</td>\n      <td>0.000000</td>\n      <td>0.111117</td>\n    </tr>\n    <tr>\n      <th>591</th>\n      <td>0.204543</td>\n      <td>0.154642</td>\n      <td>0.093023</td>\n      <td>0.083335</td>\n      <td>0.041664</td>\n      <td>0.057555</td>\n      <td>0.288892</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.116284</td>\n      <td>...</td>\n      <td>0.207179</td>\n      <td>0.000000</td>\n      <td>0.184712</td>\n      <td>0.000000</td>\n      <td>0.023254</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.494385</td>\n      <td>0.045753</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>0.159091</td>\n      <td>0.051549</td>\n      <td>0.360463</td>\n      <td>0.154767</td>\n      <td>0.374997</td>\n      <td>0.093528</td>\n      <td>0.444437</td>\n      <td>0.000000</td>\n      <td>0.046509</td>\n      <td>0.279077</td>\n      <td>...</td>\n      <td>0.011049</td>\n      <td>0.000000</td>\n      <td>0.006372</td>\n      <td>0.000000</td>\n      <td>0.139538</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.134834</td>\n      <td>0.124188</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>0.000000</td>\n      <td>0.618580</td>\n      <td>0.000000</td>\n      <td>0.119048</td>\n      <td>0.000000</td>\n      <td>0.503610</td>\n      <td>0.022221</td>\n      <td>0.272715</td>\n      <td>0.000000</td>\n      <td>0.093018</td>\n      <td>...</td>\n      <td>0.303858</td>\n      <td>0.028760</td>\n      <td>0.108283</td>\n      <td>0.005497</td>\n      <td>0.058142</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.063241</td>\n      <td>0.000000</td>\n      <td>0.117649</td>\n    </tr>\n  </tbody>\n</table>\n<p>594 rows × 192 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = processed_test_data.drop(columns=['id'])\n",
    "x_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:09:11.189011100Z",
     "start_time": "2024-03-22T22:09:11.151939700Z"
    }
   },
   "id": "e399d1e28da8c98e",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:18.185010200Z",
     "start_time": "2024-03-22T22:06:18.075129300Z"
    }
   },
   "id": "b0b701ab459f05e9",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:18.185010200Z",
     "start_time": "2024-03-22T22:06:18.077785400Z"
    }
   },
   "id": "e12a2fe5d1624af6",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Entrainement\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94f263bee9c8bdf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perceptron"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a2aab55f9768641"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:18.265351600Z",
     "start_time": "2024-03-22T22:06:18.082161700Z"
    }
   },
   "id": "25d0d42ddb3e083f",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "scikit-learn estimators should always specify their parameters in the signature of their __init__ (no varargs). <class 'src.models.perceptron_model.PerceptronModel'> with constructor (self, *args, **kwargs) doesn't  follow this convention.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 10\u001B[0m\n\u001B[0;32m      5\u001B[0m perceptron \u001B[38;5;241m=\u001B[39m PerceptronModel()\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Entraînement du modèle sur les données d'entraînement\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m \u001B[43mperceptron\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m    \n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# Prédiction sur les données d'entraînement\u001B[39;00m\n\u001B[0;32m     13\u001B[0m perceptron_pred_train \u001B[38;5;241m=\u001B[39m perceptron\u001B[38;5;241m.\u001B[39mpredict(x_train)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ift712-final-project\\.venv\\Lib\\site-packages\\sklearn\\base.py:1467\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1462\u001B[0m partial_fit_and_fitted \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1463\u001B[0m     fit_method\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpartial_fit\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m _is_fitted(estimator)\n\u001B[0;32m   1464\u001B[0m )\n\u001B[0;32m   1466\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m global_skip_validation \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m partial_fit_and_fitted:\n\u001B[1;32m-> 1467\u001B[0m     \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1472\u001B[0m     )\n\u001B[0;32m   1473\u001B[0m ):\n\u001B[0;32m   1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ift712-final-project\\.venv\\Lib\\site-packages\\sklearn\\base.py:668\u001B[0m, in \u001B[0;36mBaseEstimator._validate_params\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    658\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_params\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    659\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001B[39;00m\n\u001B[0;32m    660\u001B[0m \n\u001B[0;32m    661\u001B[0m \u001B[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    664\u001B[0m \u001B[38;5;124;03m    accepted constraints.\u001B[39;00m\n\u001B[0;32m    665\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m    666\u001B[0m     validate_parameter_constraints(\n\u001B[0;32m    667\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parameter_constraints,\n\u001B[1;32m--> 668\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdeep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m,\n\u001B[0;32m    669\u001B[0m         caller_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[0;32m    670\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\ift712-final-project\\.venv\\Lib\\site-packages\\sklearn\\base.py:243\u001B[0m, in \u001B[0;36mBaseEstimator.get_params\u001B[1;34m(self, deep)\u001B[0m\n\u001B[0;32m    228\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    229\u001B[0m \u001B[38;5;124;03mGet parameters for this estimator.\u001B[39;00m\n\u001B[0;32m    230\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    240\u001B[0m \u001B[38;5;124;03m    Parameter names mapped to their values.\u001B[39;00m\n\u001B[0;32m    241\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    242\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m()\n\u001B[1;32m--> 243\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_param_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    244\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, key)\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m deep \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(value, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget_params\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[1;32m~\\PycharmProjects\\ift712-final-project\\.venv\\Lib\\site-packages\\sklearn\\base.py:217\u001B[0m, in \u001B[0;36mBaseEstimator._get_param_names\u001B[1;34m(cls)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m parameters:\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m p\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;241m==\u001B[39m p\u001B[38;5;241m.\u001B[39mVAR_POSITIONAL:\n\u001B[1;32m--> 217\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    218\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscikit-learn estimators should always \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    219\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspecify their parameters in the signature\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    220\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m of their __init__ (no varargs).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    221\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m with constructor \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    222\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m follow this convention.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mcls\u001B[39m, init_signature)\n\u001B[0;32m    223\u001B[0m         )\n\u001B[0;32m    224\u001B[0m \u001B[38;5;66;03m# Extract and sort argument names excluding 'self'\u001B[39;00m\n\u001B[0;32m    225\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msorted\u001B[39m([p\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m parameters])\n",
      "\u001B[1;31mRuntimeError\u001B[0m: scikit-learn estimators should always specify their parameters in the signature of their __init__ (no varargs). <class 'src.models.perceptron_model.PerceptronModel'> with constructor (self, *args, **kwargs) doesn't  follow this convention."
     ]
    }
   ],
   "source": [
    "from src.models.perceptron_model import PerceptronModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Création d'un objet Perceptron\n",
    "perceptron = PerceptronModel()\n",
    "\n",
    "\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "perceptron.fit(x_train, y_train)    \n",
    "\n",
    "# Prédiction sur les données d'entraînement\n",
    "perceptron_pred_train = perceptron.predict(x_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:19.131868700Z",
     "start_time": "2024-03-22T22:06:18.086727500Z"
    }
   },
   "id": "c604625c573dd78e",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7dec7c30587233f7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calcul du taux d'erreur\n",
    "error_rate = 1 - accuracy_score(y_train, perceptron_pred_train)\n",
    "\n",
    "# Calcul de la précision\n",
    "precision = precision_score(y_train, perceptron_pred_train)\n",
    "\n",
    "# Calcul du rappel\n",
    "recall = recall_score(y_train, perceptron_pred_train)\n",
    "\n",
    "# Calcul du score F1\n",
    "f1 = f1_score(y_train, perceptron_pred_train)\n",
    "\n",
    "print(\"Taux d'erreur:\", error_rate)\n",
    "print(\"Précision:\", precision)\n",
    "print(\"Rappel:\", recall)\n",
    "print(\"Score F1:\", f1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:19.138860700Z",
     "start_time": "2024-03-22T22:06:19.131868700Z"
    }
   },
   "id": "606f0e27a6c789e4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2035af58f6f0e32b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Création d'un objet SVM avec un kernel gaussien (RBF)\n",
    "svm_classifier = SVC(kernel='rbf')\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Prédiction sur les données d'entraînement (facultatif)\n",
    "svm_pred_train = svm_classifier.predict(x_train)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-22T22:06:19.136768800Z"
    }
   },
   "id": "e6c1ca48320a8162",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db673ead39b77ae2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Création d'un objet LogisticRegression\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "logistic_regression.fit(x_train, y_train)\n",
    "\n",
    "# Prédiction sur les données d'entraînement (facultatif)\n",
    "predictions_train = logistic_regression.predict(x_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:19.139907200Z",
     "start_time": "2024-03-22T22:06:19.138860700Z"
    }
   },
   "id": "770313957263ab7d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Réseaux de neurones"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99a4914a5d166709"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Création d'un objet MLPClassifier (réseau de neurones)\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "mlp_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Prédiction sur les données d'entraînement (facultatif)\n",
    "predictions_train = mlp_classifier.predict(x_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-22T22:06:19.140950700Z"
    }
   },
   "id": "fd4357e3bb5adb65",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T22:06:19.152421Z",
     "start_time": "2024-03-22T22:06:19.143091700Z"
    }
   },
   "id": "c32be993a36e694",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
