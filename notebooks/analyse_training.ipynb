{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Methode :\n",
    "- **Support Vector Machine (SVM)** : Un algorithme de classification qui trouve l'hyperplan optimal dans un espace de grande dimension pour séparer les différentes classes. Il peut également être étendu pour gérer des problèmes non linéaires en utilisant des noyaux.\n",
    "\n",
    "- **Régression logistique** : Un algorithme utilisé pour la classification binaire (et pouvant être étendu à la classification multiclasse) en modélisant la probabilité que chaque classe soit la classe cible à l'aide d'une fonction logistique.\n",
    "- **Random Forest** : Un algorithme d'ensemble utilisé pour la classification et la régression. Il combine les prédictions de plusieurs arbres de décision pour obtenir une prédiction plus robuste et généralement de meilleure qualité.\n",
    "- **Réseaux de neurones** :\n",
    "- **Perceptron ou Multi-perceptron** :\n",
    "- **Gradient Boosting** : Un autre algorithme d'ensemble qui construit des arbres de décision de manière séquentielle, en corrigeant les erreurs des arbres précédents. Cela conduit à un modèle de prédiction puissant.\n",
    "- **Naive Bayes** : Un classificateur probabiliste simple basé sur le théorème de Bayes avec une forte indépendance entre les fonctionnalités. Il est souvent utilisé pour la classification de texte et d'autres tâches où l'indépendance des fonctionnalités est une hypothèse raisonnable.\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15caaa19a1d974d5"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-06T16:54:41.568918Z",
     "start_time": "2024-04-06T16:54:41.565280Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder ,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_dir_path = '../src/data/'\n",
    "data_trainset_cleaned = pd.read_csv(data_dir_path + \"/data_trainset_cleaned.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T16:54:44.208645Z",
     "start_time": "2024-04-06T16:54:44.185726Z"
    }
   },
   "id": "6e916a0db3fc6cbf",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing data per column after imputation:\n",
      "species      0.0\n",
      "margin1      0.0\n",
      "margin2      0.0\n",
      "margin3      0.0\n",
      "margin4      0.0\n",
      "            ... \n",
      "texture60    0.0\n",
      "texture61    0.0\n",
      "texture62    0.0\n",
      "texture63    0.0\n",
      "texture64    0.0\n",
      "Length: 187, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a copy to avoid modifying the original DataFrame\n",
    "dataset_encoded = data_trainset_cleaned.copy()\n",
    "\n",
    "# Encoding the 'species' column\n",
    "encoder = LabelEncoder()\n",
    "dataset_encoded['species'] = encoder.fit_transform(dataset_encoded['species'])\n",
    "\n",
    "# Select numeric columns except for the already encoded 'species' column for imputation\n",
    "numeric_columns = dataset_encoded.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Initialize the KNNImputer instance\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Apply imputation only on the numeric columns\n",
    "dataset_encoded[numeric_columns] = imputer.fit_transform(dataset_encoded[numeric_columns])\n",
    "\n",
    "# Convert the NumPy array returned by KNNImputer back into a pandas DataFrame and match column names\n",
    "trainset_imputed = pd.DataFrame(dataset_encoded, columns=dataset_encoded.columns)\n",
    "\n",
    "# Calculate the percentage of NaN values for each column after imputation\n",
    "na_percentage = trainset_imputed.isna().mean() * 100\n",
    "\n",
    "# Display the percentages\n",
    "print(\"Percentage of missing data per column after imputation:\")\n",
    "print(na_percentage)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T16:54:47.578954Z",
     "start_time": "2024-04-06T16:54:46.866638Z"
    }
   },
   "id": "844cbd64464a7319",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mixing and Splitting of Data "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "232ac01a61972037"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Shuffle the new dataset\n",
    "new_dataset_shuffled = shuffle(trainset_imputed)\n",
    "\n",
    "# Separate target from data\n",
    "features = trainset_imputed.drop(\"species\", axis=1)\n",
    "new_target = trainset_imputed['species']\n",
    "\n",
    "# Create training set and testing set\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, new_target, test_size=0.2, stratify=new_target\n",
    ")\n",
    "\n",
    "# Standardization of the test set\n",
    "dataset_standardized = features_test.copy()\n",
    "scaler = StandardScaler()\n",
    "dataset_standardized[features_test.columns] = scaler.fit_transform(dataset_standardized[features_test.columns])\n",
    "\n",
    "features_test_standardized = dataset_standardized\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T16:54:53.657344Z",
     "start_time": "2024-04-06T16:54:53.628903Z"
    }
   },
   "id": "4a1a8430e9211d65",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Entrainement\n",
    "\n",
    "-------------------------------------------------------\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94f263bee9c8bdf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "25cba7214c309305"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
